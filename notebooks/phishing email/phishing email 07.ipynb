{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648a8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f4ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64e5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56432551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/4y/7vss76ld1rj1ybqx7xpskc5m0000gn/T/ipykernel_3664/2648518879.py:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if row is None or row is '':\n"
     ]
    }
   ],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018b1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bc94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhenliu15471/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85bc7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"../raw_data/enron_emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3569e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9da5cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e831a198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carol,\\n\\nThanks.\\n\\nVince\\n\\n\\n\\n\\n\\n\\tCarol Coats\\n\\t10/12/2000 04:09 PM\\n\\t\\nTo: Vince J Kaminski/HOU/ECT@ECT\\ncc: Stinson Gibner/HOU/ECT@ECT \\nSubject: Re: Datren Williams Acceptance\\n  \\n\\nYou are right, Vince....Celeste and I did discuss it, and she approved his \\nFeb. start date.\\nDatren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 11/1 e-mail (excerpt below) also notes that no event of default otherwise would occur, a fact specific inquiry; e.g., debt to cap ratio upon consummation of the merger:\\n\\nTypical merger provisions provide that either (i) ENE survive or if not, (ii) \\nthe survivor be organized under U.S. (or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here's the revised form for the Blue Dog equipment:\\n\\n\\n\\nKay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLEASE SEE ATTACHED MEMO W/ATTACHMENTS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vince,\\n\\nThanks for the information.\\n\\nKathy\\n\\nAt 01:03 PM 1/8/01 -0600, you wrote:\\n\\n&gt;Kathy,\\n&gt;\\n&gt;Enron will be represented by myself (Vince Kaminski) and Kenneth Parkhill.\\n&gt;\\n&gt;Vince\\n&gt;\\n&gt;\\n&gt;\\n&gt;\\n&gt;\\n&gt;Kathy Spradling &lt;spradlin@rice.edu&gt; on 01/05/2001 05:04:21 PM\\n&gt;\\n&gt;To:   (Recipient list s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  Carol,\\n\\nThanks.\\n\\nVince\\n\\n\\n\\n\\n\\n\\tCarol Coats\\n\\t10/12/2000 04:09 PM\\n\\t\\nTo: Vince J Kaminski/HOU/ECT@ECT\\ncc: Stinson Gibner/HOU/ECT@ECT \\nSubject: Re: Datren Williams Acceptance\\n  \\n\\nYou are right, Vince....Celeste and I did discuss it, and she approved his \\nFeb. start date.\\nDatren ...\n",
       "1  The 11/1 e-mail (excerpt below) also notes that no event of default otherwise would occur, a fact specific inquiry; e.g., debt to cap ratio upon consummation of the merger:\\n\\nTypical merger provisions provide that either (i) ENE survive or if not, (ii) \\nthe survivor be organized under U.S. (or...\n",
       "2                                                                                                                                                                                                                                               Here's the revised form for the Blue Dog equipment:\\n\\n\\n\\nKay\n",
       "3                                                                                                                                                                                                                                                                      PLEASE SEE ATTACHED MEMO W/ATTACHMENTS.\n",
       "4  Vince,\\n\\nThanks for the information.\\n\\nKathy\\n\\nAt 01:03 PM 1/8/01 -0600, you wrote:\\n\\n>Kathy,\\n>\\n>Enron will be represented by myself (Vince Kaminski) and Kenneth Parkhill.\\n>\\n>Vince\\n>\\n>\\n>\\n>\\n>\\n>Kathy Spradling <spradlin@rice.edu> on 01/05/2001 05:04:21 PM\\n>\\n>To:   (Recipient list s..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9ea48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies_df.to_csv('bodies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a330d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../raw_data/fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc3600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fdb6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_bodies_df.to_csv('fraud_bodies_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a778c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1272ecdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c79827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list(['dear', 'sirmadam', 'i', 'mrpeter', 'jackson', 'shanghai', 'joysky', 'machinery', '', 'equipment', 'co', 'ltdimport', 'corporation', 'we', 'company', 'deal', 'mechanical', 'equipmenthardware', 'mineralselectrical', 'productsmedical', '', 'chemicals', 'light', 'industrial', 'products', 'office', 'equipment', 'export', 'canadaamerica', 'europewe', 'exporting', 'products', 'customers', 'europeusa', 'asian', 'countries', 'many', 'years', 'our', 'company', 'looking', 'agent', 'purchasingofficeran', 'agent', 'buying', 'materials', 'company', 'finishproduction', 'also', 'receiving', 'payments', 'products', 'suppliedyou', 'paid', 'whatever', 'transaction', 'carry', 'behalf', 'ofour', 'company', 'respect', 'buying', 'materialsequipments', 'companyas', 'well', 'recieving', 'payment', 'productsmaterials', 'supplied', 'please', 'interested', 'forward', 'us', 'full', 'name', 'phone', 'numberfax', 'andyour', 'full', 'contact', 'addresses', 'you', 'reach', 'via', 'email', '', 'peterjacksonyahoocoukthanks', 'advancemrpeter', 'jacksonmanaging', 'director'])\n",
      " list(['dear', 'sirfmadameit', 'pleasure', 'contact', 'business', 'venturec', 'son', 'josephcand', 'i', 'intend', 'establish', 'countryethough', 'i', 'met', 'i', 'believec', 'one', 'riskconfiding', 'succeed', 'sometimes', 'lifeethere', 'huge', 'amount', 'eighteen', 'million', 'ues', 'dollarccecwhich', 'late', 'husband', 'kept', 'us', 'security', 'company', 'unknown', 'persons', 'assassinated', 'himenow', 'son', 'i', 'decided', 'invest', 'money', 'country', 'oranywhere', 'safe', 'enough', 'security', 'political', 'reasonsewe', 'want', 'help', 'us', 'claim', 'retrieve', 'consignment', 'security', 'companyccould', 'please', 'notify', 'acceptance', 'carry', 'thisassistance', 'urgently', 'email', 'receipt', 'messagefkindlyc', 'acknowledge', 'receipt', 'letter', 'sending', 'email', 'copy', 'letter', 'private', 'telephone', 'and', 'fax', 'numbere', 'i', 'shallin', 'turn', 'inform', 'modalitiesee', 'telecommunicatione', 'transport', 'industrye', 'five', 'star', 'hotelif', 'assistance', 'us', 'pleased', 'offer', '', 'totalfunde', 'you', 'easily', 'reach', 'emaila', 'monicakabilasimbamailefmc', 'easily', 'reach', 'son', 'joseph', 'private', 'telephone'])\n",
      " list(['greetingcdear', 'i', 'pray', 'god', 'message', 'reaches', 'wonderful', 'spiritei', 'making', 'contact', 'based', 'trust', 'confidence', 'irrespective', 'fact', 'met', 'nature', 'situation', 'i', 'found', 'self', 'nowe', 'name', 'martin', 'goudalec', 'republic', 'cote', 'divoiree', 'got', 'email', 'address', 'internet', 'cwhen', 'searching', 'reliable', 'god', 'fearing', 'personcwho', 'betray', 'meethere', 'information', 'i', 'would', 'like', 'keep', 'confidentialethere', 'sum', 'amount', 'money', 'e', 'million', 'us', 'dollars', 'late', 'father', 'mrehassan', 'goudalec', 'chairman', 'fpresidentfceoccacaocafe', '', 'agroalimentary', 'industries', 'plcescafecao', 'deposited', 'finance', 'house', 'assassinated', 'rebels', 'sometime', 'ago', 'political', 'crisis', 'country', 'assassinated', 'other', 'government', 'officials', 'during', 'official', 'hours', 'rebel', 'troops', 'stormed', 'raided', 'cacaocafe', 'industry', 'office', 'heat', 'crisis', 'in', 'countrye', 'help', 'french', 'soldiersc', 'escaped', 'senegalc', 'noweam', 'whole', 'documents', 'concerning', 'deposit', 'made', 'investment', 'e', 'i', 'want', 'investing', 'money'])\n",
      " ...\n",
      " list(['the', 'approval', 'process', 'initiated', '', 'meeting', 'event', 'expenditures', 'excess', '', 'enabled', 'enron', 'americas', 'better', 'assess', 'business', 'value', 'events', 'accurately', 'track', 'activities', 'save', 'money', 'these', 'events', 'include', 'customer', 'employee', 'meetings', 'trade', 'shows', 'ea', 'made', 'modifications', 'process', 'described', 'memothe', '', 'threshold', 'remains', 'effect', 'customer', 'events', 'however', 'threshold', 'approval', 'employee', 'meetings', 'events', 'lowered', '', 'additional', 'requirements', 'must', 'met', 'prior', 'approvalplease', 'sure', 'follow', 'procedures', 'described', 'meetings', 'events', 'continue', 'successfully', 'manage', 'events', 'prior', 'making', 'commitments', 'customers', 'vendors', 'customer', 'events', 'anticipated', 'costs', 'excess', '', 'employee', 'events', 'anticipated', 'costs', 'excess', '', 'must', 'reviewed', 'enron', 'americas', 'public', 'relations', 'department', 'approved', 'enron', 'americas', 'office', 'chairman', 'the', 'pr', 'department', 'handle', 'site', 'search', 'hotel', 'contract', 'negotiations', 'events', 'once', 'completed', 'pr', 'department', 'work', 'plan', 'produce'])\n",
      " list(['start', 'date', '', 'hourahead', 'hour', '', 'no', 'ancillary', 'schedules', 'awarded', 'no', 'variances', 'detected', 'log', 'messagesparsing', 'file', '', 'oportlandwestdeskcalifornia', 'schedulingiso', 'final', 'schedulestxt'])\n",
      " list(['from', 'phone', 'call', 'trouble', 'opening', 'attachment', ''])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9168e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1200\n",
      "[['randythanks email yes life wild enronville it difficult decision leave group i enjoying first weeki keep via old channels company i glad worked i know continued successill give call things settle down i hope well and familymikefrom randall curryenron   amto mike mcconnellhouectectcc subject organizational announcementi vacation last week read announcment congratulations you really getting thin air now things going well here give call sometime break schedule ha i will treat lunch take carerandall currybridgeline holdings lpphone  fax  email randallcurrybhlpcom']\n",
      " ['httpwwwsmithcom']\n",
      " ['']\n",
      " ...\n",
      " ['start date  hourahead hour  no ancillary schedules awarded no variances detected log messagesparsing file  oportlandwestdeskcalifornia schedulingiso final schedulestxterror invalid variant type conversion energy importexport schedule  final schedule found preferred schedule details trans_type final sc_id ectstca mkt_type  trans_date  tie_point pverde__devers interchg_id epmi_ciso_ engy_type firm']\n",
      " ['']\n",
      " ['hi sami sorry missed call yesterday i wanted update on financial trading issues brazil and i added the working group list i going finalize swap matrix brazil on physical trading side i asked physical trading lawyer to call wondering elizabeth sager ever called emailed please let know thanks sara  forwarded sara shackletonhouect   pm mbtos  marcelo rodrigues mbtostozzinicombr   pmto sarashackletonenroncomcc andreabertoneenroncom brenthendryenroncom lynnavenenroncom rickhopkinsonenroncom afactozzinicombr krishnatozzinicombr subject re financial trading brazildear sarathank message below please find attached hereto free translation english new foreign investors regulations brazil we are preparing memo connection new regulations finalizing matrix prepared last year we send shortlykind regardsmarcelo rodrigues sara shackleton sarashackletonenroncom   pm afac marcelo i hope message finds well i would like tofinalize matrix prepared last year create abaseline']]\n",
      "[0 0 1 0 1]\n",
      "(1200,)\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data in unison with labels/header\n",
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "#idx = int(0.6*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "#train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "#valid_x, valid_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "\n",
    "\n",
    "total_size = raw_data.shape[0]\n",
    "\n",
    "# Calculate indices\n",
    "idx_train = int(0.6 * total_size)  # end of training set\n",
    "idx_val = int(0.8 * total_size)  # end of validation set\n",
    "\n",
    "# Split the data\n",
    "train_x, train_y = convert_data(raw_data[:idx_train], header[:idx_train])\n",
    "val_x, val_y = convert_data(raw_data[idx_train:idx_val], header[idx_train:idx_val])\n",
    "test_x, test_y = convert_data(raw_data[idx_val:], header[idx_val:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8493a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f768ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319098a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51649a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1a340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f0a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3008d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e3863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cf154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc4480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5154a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc05e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3f47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6f2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae935cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e911e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee082754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7613f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_data_analytics",
   "language": "python",
   "name": "adv_data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
